# ğŸ¤– GLM Hybrid Orchestration - Agent-Friendly Setup Guide

> **Bu dosyayÄ± Claude Code'a okut ve "Bu sistemi kur" de. Otonom olarak tÃ¼m kurulumu yapacaktÄ±r.**

---

## ğŸ“‹ Ã–zet

Bu rehber, Claude Code (Opus/Sonnet) ile Z.AI GLM modellerini hibrit bir ÅŸekilde kullanmanÄ± saÄŸlar:
- **Opus**: Orchestrator (planlama, review, tool kullanÄ±mÄ±)
- **GLM**: Worker (kod yazma, generation, boilerplate)
- **Maliyet optimizasyonu**: AÄŸÄ±r iÅŸler ucuz GLM'e delege edilir

---

## ğŸš€ AGENT KURULUM PROMPT'U

AÅŸaÄŸÄ±daki prompt'u Claude Code'a ver:

```
Bu AGENT-SETUP-GUIDE.md dosyasÄ±nÄ± oku ve GLM Hybrid Orchestration sistemini kur:
1. Gerekli dosyalarÄ± oluÅŸtur
2. MCP server'Ä± kaydet
3. CLAUDE.md'ye kurallarÄ± ekle
4. Test et ve doÄŸrula
```

---

## ğŸ“ Dosya YapÄ±sÄ±

```
~/projects/ccglm-mcp/           # Ana dizin
â”œâ”€â”€ ccglm_mcp_server.py         # MCP Server (ana dosya)
â”œâ”€â”€ .env                        # API credentials (GÄ°ZLÄ°)
â”œâ”€â”€ .env.example                # Ã–rnek .env
â”œâ”€â”€ requirements.txt            # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ test_server.py              # Test suite
â””â”€â”€ README.md                   # DokÃ¼mantasyon

~/.claude/
â”œâ”€â”€ settings.json               # MCP server kaydÄ±
â””â”€â”€ CLAUDE.md                   # GLM routing kurallarÄ±
```

---

## ğŸ”§ KURULUM ADIMLARI

### AdÄ±m 1: Repository'yi Klonla

```bash
cd ~/projects
git clone https://github.com/CyPack/ccglm-mcp.git
cd ccglm-mcp
```

### AdÄ±m 2: Python BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± Kur

```bash
pip install -r requirements.txt
```

**requirements.txt iÃ§eriÄŸi:**
```
mcp>=1.0.0
python-dotenv>=1.0.0
```

### AdÄ±m 3: API Credentials Ayarla

`.env` dosyasÄ± oluÅŸtur:

```bash
cat > .env << 'EOF'
# Z.AI GLM Configuration
GLM_BASE_URL=https://api.z.ai/api/anthropic
GLM_AUTH_TOKEN=YOUR_API_TOKEN_HERE
EOF
chmod 600 .env
```

> âš ï¸ `YOUR_API_TOKEN_HERE` kÄ±smÄ±nÄ± kendi Z.AI API token'Ä±nla deÄŸiÅŸtir.
> Token almak iÃ§in: https://z.ai adresinden kayÄ±t ol.

### AdÄ±m 4: MCP Server'Ä± Kaydet

`~/.claude.json` dosyasÄ±na ekle (veya oluÅŸtur):

```json
{
  "mcpServers": {
    "ccglm-mcp": {
      "type": "stdio",
      "command": "python3",
      "args": ["/FULL/PATH/TO/ccglm-mcp/ccglm_mcp_server.py"],
      "env": {}
    }
  }
}
```

> âš ï¸ `/FULL/PATH/TO/` kÄ±smÄ±nÄ± kendi path'inle deÄŸiÅŸtir (Ã¶rn: `/home/username/projects/`)

**Veya CLI ile:**
```bash
# Mevcut config'i kontrol et
cat ~/.claude.json | jq '.mcpServers'

# Manuel ekle veya Claude Code'a "MCP server kaydet" de
```

### AdÄ±m 5: CLAUDE.md'ye GLM KurallarÄ±nÄ± Ekle

`~/.claude/CLAUDE.md` dosyasÄ±na aÅŸaÄŸÄ±daki bÃ¶lÃ¼mÃ¼ ekle:

```markdown
---

## ğŸ¤– GLM HYBRID ORCHESTRATION

### Mimari: Opus Master + GLM Worker

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OPUS (Orchestrator)                       â”‚
â”‚  â€¢ GÃ¶rev analizi ve planlama                                â”‚
â”‚  â€¢ Kod review ve kalite kontrolÃ¼                            â”‚
â”‚  â€¢ KarmaÅŸÄ±k reasoning ve karar verme                        â”‚
â”‚  â€¢ Tool kullanÄ±mÄ± (MCP, file ops, git)                      â”‚
â”‚  â€¢ SonuÃ§ birleÅŸtirme ve raporlama                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ Delege
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GLM (Worker)                              â”‚
â”‚  â€¢ Kod yazma/generation                                      â”‚
â”‚  â€¢ Refactoring gÃ¶revleri                                    â”‚
â”‚  â€¢ Boilerplate oluÅŸturma                                    â”‚
â”‚  â€¢ Documentation yazma                                       â”‚
â”‚  â€¢ Test case generation                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GLM Trigger'larÄ±

| Trigger | Mod | DavranÄ±ÅŸ |
|---------|-----|----------|
| `#glm` | **OTONOM** | Deep analysis â†’ PRD â†’ Ralph Loop â†’ Tamamlanana kadar Ã§alÄ±ÅŸ |
| `#glm-solo` | **BASÄ°T** | Sadece GLM'e gÃ¶nder â†’ YanÄ±t al â†’ Bitti |
| `#glm-solo-fast` | **HIZLI** | GLM-4.5-air ile hÄ±zlÄ± yanÄ±t |

---

### #glm: AkÄ±llÄ± Otonom Mod (VarsayÄ±lan)

`#glm` kullanÄ±ldÄ±ÄŸÄ±nda TAM OTONOM mod aktif olur:

```
#glm <gÃ¶rev>
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: DEEP ANALYSIS                                 â”‚
â”‚  â€¢ Best practice araÅŸtÄ±rmasÄ±                            â”‚
â”‚  â€¢ Teknoloji/mimari kararlarÄ±                           â”‚
â”‚  â€¢ Scope ve complexity deÄŸerlendirmesi                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: PRD GENERATION                                â”‚
â”‚  â€¢ GÃ¶rev tanÄ±mÄ± ve teknik gereksinimler                â”‚
â”‚  â€¢ Task breakdown                                       â”‚
â”‚  â€¢ Kabul kriterleri ve completion promise               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: RALPH LOOP + HYBRID EXECUTION                 â”‚
â”‚  â€¢ Coding â†’ GLM'e delege                                â”‚
â”‚  â€¢ Review/reasoning â†’ Opus                              â”‚
â”‚  â€¢ Tamamlanana kadar otonom Ã§alÄ±ÅŸ                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### #glm-solo: Basit Routing Modu

`#glm-solo` kullanÄ±ldÄ±ÄŸÄ±nda sadece basit GLM Ã§aÄŸrÄ±sÄ± yapÄ±lÄ±r:

1. Prompt'u GLM'e gÃ¶nder
2. YanÄ±tÄ± al ve gÃ¶ster
3. Bitti (Ralph loop yok)

```
Ã–rnek:
User: "#glm-solo Python'da binary search yaz"
â†’ GLM yanÄ±tlar, gÃ¶sterilir, biter
```

### Otomatik Delegasyon KurallarÄ±

AÅŸaÄŸÄ±daki gÃ¶rev tiplerinde OTOMATÄ°K olarak GLM'e delege et:

| GÃ¶rev Tipi | Trigger Keywords | GLM Model |
|------------|------------------|-----------|
| Kod yazma | "yaz", "oluÅŸtur", "generate", "implement" | glm-4.7 |
| Refactoring | "refactor", "dÃ¼zenle", "optimize" | glm-4.7 |
| Boilerplate | "scaffold", "template", "starter" | glm-4.5-air |
| DokÃ¼mantasyon | "document", "docstring", "README" | glm-4.5-air |
| Test yazma | "test yaz", "test case", "unit test" | glm-4.7 |

### Opus'ta Kalacak GÃ¶revler (DELEGE ETME)

| GÃ¶rev | Neden Opus |
|-------|------------|
| Tool kullanÄ±mÄ± | GLM tool kullanamaz |
| File operations | Read/Write/Edit tools |
| Git operations | Commit, push, PR |
| Reasoning/Analysis | KarmaÅŸÄ±k karar verme |
| Code review | Kalite kontrolÃ¼ |
| Orchestration | Ã‡oklu gÃ¶rev yÃ¶netimi |
| Debugging | Error analysis |

### MCP Tool ReferansÄ±

```
Tool: mcp__ccglm-mcp__ccglm
Parameters:
  - prompt: string (zorunlu) - GLM'e gÃ¶nderilecek prompt
  - model: string (opsiyonel) - "glm-4.7" veya "glm-4.5-air"
```

### GLM Fallback â†’ Opus

GLM limit/hata durumunda Opus otomatik devam eder:

```
GLM FALLBACK RULES:

1. GLM Ã‡aÄŸrÄ±sÄ± BaÅŸarÄ±sÄ±z Olursa:
   â”œâ”€â”€ Rate limit (429) â†’ Opus devam eder
   â”œâ”€â”€ Timeout â†’ Opus devam eder
   â”œâ”€â”€ Connection error â†’ Opus devam eder
   â””â”€â”€ API error â†’ Opus devam eder

2. Fallback AkÄ±ÅŸÄ±:
   GLM Ã§aÄŸrÄ±sÄ± yap â†’ BaÅŸarÄ±sÄ±z mÄ±? â†’ Opus devam et
   Log: "âš ï¸ GLM limit/hata, Opus olarak devam ediyorum"
```

### Ã–rnek KullanÄ±mlar

```
# OTONOM MOD - analiz, PRD, Ralph Loop, tamamlanana kadar Ã§alÄ±ÅŸ
User: "#glm REST API endpoint yaz"
â†’ Deep analysis yapar
â†’ PRD oluÅŸturur
â†’ Ralph loop baÅŸlatÄ±r
â†’ Kod yazar, test eder, tamamlar

# BASÄ°T MOD - sadece GLM'e sor
User: "#glm-solo Fibonacci fonksiyonu yaz"
â†’ GLM'e gÃ¶nderir
â†’ YanÄ±tÄ± gÃ¶sterir
â†’ Bitti

# HIZLI BASÄ°T MOD
User: "#glm-solo-fast Merhaba de"
â†’ GLM-4.5-air ile hÄ±zlÄ± yanÄ±t
â†’ Bitti
```
```

### AdÄ±m 6: Claude Code'u Yeniden BaÅŸlat

```bash
# Terminal'i kapat ve yeniden aÃ§
# veya
claude --version  # MCP server'larÄ±n yÃ¼klendiÄŸini doÄŸrula
```

### AdÄ±m 7: Test Et

```bash
# Test suite Ã§alÄ±ÅŸtÄ±r
cd ~/projects/ccglm-mcp
python3 test_server.py
```

**Claude Code iÃ§inde test:**
```
#glm-solo Merhaba, kendini tanÄ±t
```

YanÄ±t alÄ±yorsan kurulum baÅŸarÄ±lÄ±! âœ…

> **Not:** `#glm` (otonom mod) Ralph Loop baÅŸlatÄ±r. Basit test iÃ§in `#glm-solo` kullan.

---

## ğŸ¯ KULLANIM Ã–RNEKLERÄ°

### Otonom Mod (#glm) - Tam GÃ¼Ã§

```
#glm REST API endpoint yaz
#glm Login sistemi implement et
#glm Kanban dashboard oluÅŸtur
#glm CSV parser yaz ve test et
```

Bu mod:
- Deep analysis yapar
- PRD oluÅŸturur
- Ralph loop baÅŸlatÄ±r
- Tamamlanana kadar otonom Ã§alÄ±ÅŸÄ±r

### Basit Mod (#glm-solo) - HÄ±zlÄ± YanÄ±t

```
#glm-solo Python'da quick sort yaz
#glm-solo Bu fonksiyonu aÃ§Ä±kla
#glm-solo Regex pattern Ã¶ner
```

Bu mod sadece GLM'e sorar ve yanÄ±tÄ± gÃ¶sterir.

### HÄ±zlÄ± Basit Mod (#glm-solo-fast)

```
#glm-solo-fast Merhaba de
#glm-solo-fast 1+1 kaÃ§?
```

GLM-4.5-air modeli ile Ã§ok hÄ±zlÄ± yanÄ±t alÄ±r.

---

## ğŸ” TROUBLESHOOTING

### MCP Tool GÃ¶rÃ¼nmÃ¼yor

1. `~/.claude.json` dosyasÄ±nÄ± kontrol et
2. Path'in doÄŸru olduÄŸundan emin ol
3. Claude Code'u yeniden baÅŸlat

### GLM Timeout

- Uzun promptlarda timeout olabilir
- `glm-4.5-air` daha hÄ±zlÄ±, timeout riski dÃ¼ÅŸÃ¼k
- Fallback aktif: Opus otomatik devam eder

### API Token HatasÄ±

1. `.env` dosyasÄ±nÄ± kontrol et
2. Token'Ä±n geÃ§erli olduÄŸunu doÄŸrula
3. Z.AI hesabÄ±nda kredi olduÄŸundan emin ol

---

## ğŸ“Š MÄ°MARÄ° DÄ°YAGRAM

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER                                     â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                 CLAUDE CODE (Opus/Sonnet)                  â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚   #glm detected? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚  â”‚
â”‚  â”‚        â”‚                                    â”‚              â”‚  â”‚
â”‚  â”‚        â–¼                                    â–¼              â”‚  â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚  â”‚
â”‚  â”‚   â”‚  OPUS   â”‚â—„â”€â”€ Fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    GLM    â”‚        â”‚  â”‚
â”‚  â”‚   â”‚ Master  â”‚                        â”‚  Worker   â”‚        â”‚  â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â”‚  â”‚
â”‚  â”‚        â”‚                                   â”‚              â”‚  â”‚
â”‚  â”‚        â–¼                                   â–¼              â”‚  â”‚
â”‚  â”‚   â€¢ Planning          MCP Tool:  mcp__ccglm-mcp__ccglm   â”‚  â”‚
â”‚  â”‚   â€¢ Review                   â”‚                            â”‚  â”‚
â”‚  â”‚   â€¢ Tool use                 â–¼                            â”‚  â”‚
â”‚  â”‚   â€¢ Git ops           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚  â”‚
â”‚  â”‚                       â”‚ Z.AI GLM APIâ”‚                     â”‚  â”‚
â”‚  â”‚                       â”‚  glm-4.7    â”‚                     â”‚  â”‚
â”‚  â”‚                       â”‚glm-4.5-air  â”‚                     â”‚  â”‚
â”‚  â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ DOSYA Ä°Ã‡ERÄ°KLERÄ°

### ccglm_mcp_server.py (Ana Kod)

```python
#!/usr/bin/env python3
"""
CCGLM MCP Server - Routes prompts to GLM via Claude CLI with Z.AI credentials
"""

import asyncio
import os
import sys
import time
from typing import Any, Dict, List, Set
from dotenv import load_dotenv

import mcp.server.stdio
import mcp.types as types
from mcp.server import Server

load_dotenv()

# Configuration
DEFAULT_TIMEOUT = 300
MAX_TIMEOUT = 600
GLM_BASE_URL = os.getenv("GLM_BASE_URL", "https://api.z.ai/api/anthropic")
GLM_AUTH_TOKEN = os.getenv("GLM_AUTH_TOKEN")

server = Server("ccglm-mcp")

@server.list_tools()
async def list_tools() -> List[types.Tool]:
    return [
        types.Tool(
            name="ccglm",
            description="Route prompt to GLM-4.7 (default) or glm-4.5-air (fast)",
            inputSchema={
                "type": "object",
                "properties": {
                    "prompt": {"type": "string", "description": "Prompt to send to GLM"},
                    "model": {
                        "type": "string",
                        "description": "GLM model to use",
                        "default": "glm-4.7",
                        "enum": ["glm-4.7", "glm-4.5-air"]
                    }
                },
                "required": ["prompt"]
            }
        )
    ]

@server.call_tool()
async def call_tool(name: str, arguments: Dict[str, Any]) -> List[types.TextContent]:
    if name == "ccglm":
        result = await ccglm_route(arguments)
        if "error" in result:
            return [types.TextContent(type="text", text=f"âŒ Error: {result['error']}")]
        return [types.TextContent(type="text", text=result.get("response", "No response"))]
    return [types.TextContent(type="text", text=f"Unknown tool: {name}")]

async def ccglm_route(args: Dict[str, Any]) -> Dict[str, Any]:
    prompt = args.get("prompt", "")
    model = args.get("model", "glm-4.7")

    if not prompt:
        return {"error": "No prompt provided"}

    env = os.environ.copy()
    env["ANTHROPIC_BASE_URL"] = GLM_BASE_URL
    env["ANTHROPIC_AUTH_TOKEN"] = GLM_AUTH_TOKEN
    env["ANTHROPIC_MODEL"] = model

    timeout = 120 if model == "glm-4.5-air" else DEFAULT_TIMEOUT

    cmd = ["claude", "--dangerously-skip-permissions", "-c", "-p"]

    process = await asyncio.create_subprocess_exec(
        *cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
        stdin=asyncio.subprocess.PIPE,
        env=env
    )

    try:
        stdout, stderr = await asyncio.wait_for(
            process.communicate(input=prompt.encode('utf-8')),
            timeout=timeout
        )
        return {"response": stdout.decode('utf-8', errors='replace').strip()}
    except asyncio.TimeoutError:
        process.kill()
        return {"error": f"Timeout after {timeout}s"}

async def main():
    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):
        await server.run(read_stream, write_stream, server.create_initialization_options())

if __name__ == "__main__":
    asyncio.run(main())
```

### .env.example

```bash
# Z.AI GLM Configuration
# Get your token from https://z.ai
GLM_BASE_URL=https://api.z.ai/api/anthropic
GLM_AUTH_TOKEN=your_api_token_here
```

### requirements.txt

```
mcp>=1.0.0
python-dotenv>=1.0.0
```

---

## âœ… KURULUM KONTROL LÄ°STESÄ°

Agent iÃ§in kontrol listesi:

- [ ] Repository klonlandÄ±
- [ ] Python baÄŸÄ±mlÄ±lÄ±klarÄ± kuruldu (`pip install -r requirements.txt`)
- [ ] `.env` dosyasÄ± oluÅŸturuldu ve token eklendi
- [ ] `.env` dosyasÄ± `chmod 600` ile korunuyor
- [ ] MCP server `~/.claude.json`'a kaydedildi
- [ ] CLAUDE.md'ye GLM kurallarÄ± eklendi
- [ ] Claude Code yeniden baÅŸlatÄ±ldÄ±
- [ ] `#glm test` ile test edildi ve yanÄ±t alÄ±ndÄ±
- [ ] `python3 test_server.py` tÃ¼m testler geÃ§ti

---

## ğŸ”— KAYNAKLAR

- **Repository:** https://github.com/CyPack/ccglm-mcp
- **Z.AI:** https://z.ai
- **MCP Protocol:** https://github.com/anthropics/mcp

---

## ğŸ“„ LÄ°SANS

Bu proje MIT lisansÄ± altÄ±nda sunulmaktadÄ±r.

---

**Son GÃ¼ncelleme:** 2026-02-01
**Versiyon:** 1.0.0
